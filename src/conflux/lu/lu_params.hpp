#pragma once
#include <tuple>
#include <vector>
#include <mpi.h>
#include <costa/layout.hpp>

namespace conflux {
template <typename T>
class lu_params {
   private:
       std::tuple<int, int, int> p2X(MPI_Comm comm3D, int rank) {
           int coords[] = {-1, -1, -1};
           MPI_Cart_coords(comm3D, rank, 3, coords);
           return {coords[0], coords[1], coords[2]};
       }
       int X2p(MPI_Comm comm3D, int pi, int pj, int pk) {
           int coords[] = {pi, pj, pk};
           int rank;
           MPI_Cart_rank(comm3D, coords, &rank);
           return rank;
       }
       std::tuple<int, int, int> get_p_grid(int M, int N, int P) {
        double ratio = 1.0 * std::max(M, N) / std::min(M, N);
        int p1 = (int)std::cbrt(P / ratio);

        int Px = p1;
        int Py = ratio * p1;
        int Pz = P / (Px * Py);

        // sort the values
        std::vector<int> dims = {Px, Py, Pz};
        std::sort(dims.rbegin(), dims.rend());

        Px = dims[0];
        Py = dims[1];
        Pz = dims[2];

        return {Px, Py, Pz};
    }

    void initialize(int inpM, int inpN, int v, int Px, int Py, int Pz, MPI_Comm comm) {
        this->Px = Px;
        this->Py = Py;
        this->Pz = Pz;

        P = Px * Px * Pz;

        this->v = v;

        int nLocalTilesx = (int)(std::ceil((double)inpM / (v * Px)));
        int nLocalTilesy = (int)(std::ceil((double)inpN / (v * Py)));

        M = v * Px * nLocalTilesx;
        N = v * Py * nLocalTilesy;

        nlayr = (int)((v + Pz - 1) / Pz);

        Nt = (int)(std::ceil((double)N / v));
        Mt = (int)(std::ceil((double)M / v));
        t = (int)(std::ceil((double)Nt / Py)) + 1ll;
        tA11x = (int)(std::ceil((double)Mt / Px));
        tA11y = (int)(std::ceil((double)Nt / Py));

        Ml = tA11x * v;
        Nl = tA11y * v;

        // the main 3D communicator
        int dim[] = {Px, Py, Pz};  // 3D processor grid
        int period[] = {0, 0, 0};
        int reorder = 1;
        MPI_Cart_create(comm, 3, dim, period, reorder, &lu_comm);

        // jk communicator
        int keep_dims_jk[] = {0, 1, 1};
        MPI_Cart_sub(lu_comm, keep_dims_jk, &jk_comm);

        // k-communicator
        int keep_dims_k[] = {0, 0, 1};
        MPI_Cart_sub(lu_comm, keep_dims_k, &k_comm);

        // initialize coordinates
        MPI_Comm_rank(lu_comm, &rank);
        std::tie(pi, pj, pk) = p2X(lu_comm, rank);

        // create COSTA layout descriptor
        data = std::vector<T>(Ml * Nl);

        std::vector<costa::block_t> local_blocks;
        int n_local_blocks = tA11x * tA11y;
        local_blocks.reserve(n_local_blocks);

        for (int lti = 0; lti < tA11x; ++lti) {
            auto gti = lti * Px + pi;
            for (int ltj = 0; ltj < tA11y; ++ltj) {
                auto gtj = ltj * Py + pj;
                costa::block_t block;
                block.data = &data[lti * v * Nl + ltj * v];
                block.ld = Nl;
                block.row = gti;
                block.col = gtj;
                local_blocks.push_back(block);
            }
        }

        std::vector<int> row_splits = line_split(M, v);
        std::vector<int> col_splits = line_split(N, v);

        std::vector<int> owners(Mt*Nt);

        for (int i = 0; i < Mt; ++i) {
            for (int j = 0; j < Nt; ++j) {
                int ij = i * Nt + j;
                owners[ij] = X2p(lu_comm, pi, pj, 0);
            }
        }

        matrix = costa::custom_layout<T>(
                Mt, Nt, // num of global blocks
                &row_splits[0], &col_splits[0], // splits in the global matrix
                &owners[0], // ranks owning each tile
                n_local_blocks, // num of local blocks
                &local_blocks[0], // local blocks
                'R' // row-major ordering within blocks
                );

        InitMatrix();
    }

public:
    std::vector<int> line_split(int N, int v) {
        std::vector<int> splits;
        splits.reserve(N/v + 1);
        for (int i = 0; i < N/v; ++i) {
            splits.push_back(i * v);
        }
        splits.push_back(N);
        return splits;
    }

    void InitMatrix() {
        if (N == 16 && M == 16) {
            std::vector<T> generator = {
                1, 8, 2, 7, 3, 8, 2, 4, 8, 7, 5, 5, 1, 4, 4, 9,
                8, 4, 9, 2, 8, 6, 9, 9, 3, 7, 7, 7, 8, 7, 2, 8,
                3, 5, 4, 8, 9, 2, 7, 1, 2, 2, 7, 9, 8, 2, 1, 3,
                6, 4, 1, 5, 3, 7, 9, 1, 1, 3, 2, 9, 9, 5, 1, 9,
                8, 7, 100, 2, 9, 1, 1, 9, 3, 5, 8, 8, 5, 5, 3, 3,
                4, 2, 900, 3, 7, 3, 4, 5, 1, 9, 7, 7, 2, 4, 5, 2,  //pi=0, pj=1 owner of 900
                1, 9, 8, 3, 5, 5, 1, 3, 6, 8, 3, 4, 3, 9, 1, 9,
                3, 9, 2, 7, 9, 2, 3, 9, 8, 6, 3, 5, 5, 2, 2, 9,
                9, 9, 5, 4, 3, 4, 6, 6, 9, 2, 1, 5, 6, 9, 5, 7,
                3, 2, 4, 5, 2, 4, 5, 3, 6, 5, 2, 6, 2, 7, 8, 2,
                4, 4, 4, 5, 2, 5, 3, 4, 1, 7, 8, 1, 8, 8, 5, 4,
                4, 5, 9, 5, 7, 9, 2, 9, 4, 6, 4, 3, 5, 8, 1, 2,
                7, 8, 1, 4, 7, 6, 5, 7, 1, 2, 7, 3, 8, 1, 4, 4,
                7, 6, 7, 8, 2, 2, 4, 6, 6, 8, 3, 6, 5, 2, 6, 5,
                4, 5, 1, 5, 3, 7, 4, 4, 7, 5, 8, 2, 4, 7, 1, 7,
                8, 3, 2, 4, 3, 8, 1, 6, 9, 6, 3, 6, 4, 8, 7, 8};

            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);

        } else if (N == 27 && M == 27) {
            std::vector<T> generator = {4.0, 2.0, 0.0, 7.0, 0.0, 0.0, 1.0, 5.0, 4.0, 6.0, 8.0, 7.0, 0.0, 4.0, 3.0, 5.0, 3.0, 4.0, 0.0, 1.0, 1.0, 6.0, 7.0, 1.0, 8.0, 2.0, 3.0,
                                9.0, 0.0, 7.0, 2.0, 400.0, 3.0, 2.0, 8.0, 2.0, 9.0, 6.0, 3.0, 6.0, 6.0, 7.0, 9.0, 5.0, 2.0, 0.0, 7.0, 0.0, 2.0, 8.0, 8.0, 9.0, 4.0, 5.0,
                                1.0, 5.0, 3.0, 7.0, 1.0, 7.0, 0.0, 5.0, 0.0, 1.0, 3.0, 6.0, 7.0, 7.0, 7.0, 6.0, 9.0, 7.0, 9.0, 7.0, 5.0, 6.0, 2.0, 3.0, 5.0, 4.0, 4.0,
                                7.0, 7.0, 6.0, 9.0, 1.0, 6.0, 9.0, 3.0, 8.0, 9.0, 9.0, 3.0, 5.0, 5.0, 2.0, 1.0, 5.0, 8.0, 6.0, 8.0, 3.0, 0.0, 6.0, 2.0, 9.0, 9.0, 0.0,
                                7.0, 6.0, 7.0, 8.0, 7.0, 1.0, 7.0, 2.0, 1.0, 7.0, 2.0, 6.0, 8.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 5.0, 9.0, 4.0, 6.0, 3.0, 5.0, 6.0, 2.0,
                                5.0, 0.0, 1.0, 0.0, 2.0, 1.0, 5.0, 4.0, 1.0, 5.0, 6.0, 0.0, 8.0, 5.0, 6.0, 0.0, 6.0, 7.0, 4.0, 0.0, 9.0, 6.0, 1.0, 3.0, 5.0, 6.0, 8.0,
                                1.0, 0.0, 1.0, 3.0, 6.0, 0.0, 3.0, 4.0, 6.0, 4.0, 6.0, 9.0, 6.0, 5.0, 4.0, 5.0, 3.0, 1.0, 1.0, 9.0, 2.0, 9.0, 4.0, 5.0, 3.0, 7.0, 0.0,
                                5.0, 7.0, 5.0, 3.0, 9.0, 0.0, 1.0, 3.0, 8.0, 2.0, 3.0, 8.0, 1.0, 0.0, 6.0, 4.0, 7.0, 8.0, 2.0, 8.0, 8.0, 8.0, 2.0, 5.0, 4.0, 3.0, 8.0,
                                2.0, 9.0, 4.0, 6.0, 4.0, 4.0, 6.0, 5.0, 5.0, 7.0, 1.0, 7.0, 2.0, 7.0, 2.0, 9.0, 4.0, 1.0, 2.0, 2.0, 8.0, 4.0, 7.0, 3.0, 4.0, 5.0, 0.0,
                                1.0, 5.0, 8.0, 5.0, 6.0, 6.0, 9.0, 7.0, 7.0, 2.0, 0.0, 8.0, 1.0, 9.0, 1.0, 8.0, 4.0, 5.0, 3.0, 5.0, 5.0, 7.0, 2.0, 3.0, 0.0, 5.0, 6.0,
                                2.0, 1.0, 7.0, 7.0, 7.0, 7.0, 1.0, 4.0, 1.0, 0.0, 4.0, 3.0, 0.0, 3.0, 8.0, 4.0, 6.0, 3.0, 1.0, 9.0, 8.0, 4.0, 8.0, 5.0, 8.0, 1.0, 5.0,
                                8.0, 8.0, 7.0, 3.0, 4.0, 5.0, 2.0, 4.0, 9.0, 7.0, 1.0, 6.0, 1.0, 9.0, 7.0, 8.0, 9.0, 8.0, 3.0, 7.0, 9.0, 9.0, 8.0, 6.0, 0.0, 5.0, 2.0,
                                0.0, 3.0, 0.0, 2.0, 6.0, 1.0, 3.0, 1.0, 5.0, 6.0, 7.0, 5.0, 6.0, 3.0, 9.0, 1.0, 3.0, 5.0, 1.0, 8.0, 5.0, 9.0, 3.0, 9.0, 4.0, 6.0, 5.0,
                                2.0, 2.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 6.0, 7.0, 3.0, 5.0, 9.0, 8.0, 1.0, 3.0, 8.0, 4.0, 8.0, 4.0, 7.0, 8.0, 4.0, 7.0, 8.0, 4.0, 1.0,
                                0.0, 7.0, 0.0, 7.0, 9.0, 1.0, 6.0, 2.0, 0.0, 6.0, 8.0, 2.0, 3.0, 4.0, 1.0, 9.0, 7.0, 8.0, 0.0, 4.0, 5.0, 3.0, 6.0, 4.0, 3.0, 8.0, 6.0,
                                4.0, 0.0, 7.0, 2.0, 1.0, 1.0, 4.0, 3.0, 8.0, 4.0, 7.0, 2.0, 4.0, 4.0, 0.0, 9.0, 9.0, 3.0, 9.0, 5.0, 0.0, 4.0, 8.0, 8.0, 6.0, 7.0, 5.0,
                                0.0, 0.0, 9.0, 3.0, 2.0, 0.0, 9.0, 6.0, 7.0, 3.0, 5.0, 4.0, 9.0, 2.0, 4.0, 7.0, 0.0, 4.0, 3.0, 2.0, 4.0, 2.0, 6.0, 1.0, 8.0, 3.0, 0.0,
                                8.0, 6.0, 6.0, 5.0, 7.0, 1.0, 4.0, 9.0, 1.0, 8.0, 1.0, 2.0, 9.0, 1.0, 1.0, 6.0, 3.0, 9.0, 0.0, 7.0, 6.0, 7.0, 5.0, 0.0, 8.0, 4.0, 0.0,
                                1.0, 6.0, 1.0, 2.0, 4.0, 1.0, 6.0, 9.0, 5.0, 3.0, 9.0, 8.0, 6.0, 3.0, 8.0, 3.0, 6.0, 0.0, 3.0, 5.0, 5.0, 8.0, 3.0, 0.0, 9.0, 3.0, 1.0,
                                0.0, 5.0, 7.0, 6.0, 7.0, 1.0, 1.0, 4.0, 3.0, 8.0, 2.0, 9.0, 9.0, 7.0, 0.0, 9.0, 2.0, 9.0, 7.0, 6.0, 3.0, 9.0, 4.0, 1.0, 1.0, 7.0, 0.0,
                                3.0, 7.0, 1.0, 4.0, 3.0, 3.0, 3.0, 2.0, 5.0, 7.0, 9.0, 0.0, 7.0, 7.0, 0.0, 1.0, 2.0, 1.0, 7.0, 3.0, 9.0, 5.0, 7.0, 3.0, 2.0, 7.0, 4.0,
                                4.0, 7.0, 1.0, 1.0, 2.0, 3.0, 1.0, 7.0, 3.0, 8.0, 2.0, 5.0, 3.0, 6.0, 5.0, 7.0, 7.0, 6.0, 5.0, 1.0, 8.0, 5.0, 8.0, 3.0, 8.0, 4.0, 8.0,
                                1.0, 7.0, 6.0, 7.0, 0.0, 2.0, 7.0, 7.0, 4.0, 5.0, 3.0, 0.0, 6.0, 0.0, 7.0, 6.0, 6.0, 5.0, 6.0, 4.0, 8.0, 1.0, 7.0, 0.0, 5.0, 6.0, 6.0,
                                9.0, 2.0, 3.0, 1.0, 6.0, 2.0, 8.0, 7.0, 1.0, 6.0, 0.0, 8.0, 2.0, 8.0, 3.0, 8.0, 5.0, 6.0, 8.0, 3.0, 3.0, 8.0, 0.0, 5.0, 5.0, 9.0, 5.0,
                                3.0, 6.0, 6.0, 2.0, 4.0, 8.0, 3.0, 7.0, 2.0, 9.0, 6.0, 9.0, 2.0, 9.0, 1.0, 3.0, 6.0, 3.0, 0.0, 7.0, 5.0, 4.0, 6.0, 0.0, 6.0, 7.0, 8.0,
                                2.0, 5.0, 7.0, 2.0, 4.0, 7.0, 6.0, 1.0, 0.0, 4.0, 1.0, 0.0, 6.0, 7.0, 3.0, 7.0, 0.0, 6.0, 3.0, 7.0, 8.0, 2.0, 4.0, 1.0, 8.0, 7.0, 0.0,
                                0.0, 3.0, 5.0, 5.0, 6.0, 5.0, 2.0, 6.0, 9.0, 0.0, 0.0, 9.0, 5.0, 0.0, 2.0, 8.0, 3.0, 8.0, 0.0, 6.0, 9.0, 8.0, 4.0, 6.0, 5.0, 1.0, 9.0};

            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);
        } else if (N == 32 && M == 32) {
            std::vector<T> generator = {9.0, 4.0, 8.0, 8.0, 3.0, 8.0, 0.0, 5.0, 2.0, 1.0, 0.0, 6.0, 3.0, 7.0, 0.0, 3.0, 5.0, 7.0, 3.0, 6.0, 8.0, 6.0, 2.0, 0.0, 8.0, 0.0, 8.0, 5.0, 9.0, 7.0, 9.0, 3.0,
                                  7.0, 4.0, 4.0, 6.0, 8.0, 9.0, 7.0, 4.0, 4.0, 7.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 0.0, 9.0, 4.0, 3.0, 6.0, 2.0, 9.0, 7.0, 0.0, 4.0, 8.0, 9.0, 4.0, 6.0, 1.0,
                                  9.0, 2.0, 9.0, 6.0, 6.0, 5.0, 2.0, 1.0, 2.0, 1.0, 7.0, 3.0, 0.0, 9.0, 8.0, 9.0, 9.0, 1.0, 3.0, 7.0, 6.0, 1.0, 8.0, 2.0, 2.0, 5.0, 5.0, 5.0, 0.0, 8.0, 2.0, 1.0,
                                  8.0, 9.0, 8.0, 8.0, 6.0, 5.0, 0.0, 4.0, 3.0, 2.0, 7.0, 4.0, 0.0, 2.0, 6.0, 0.0, 8.0, 4.0, 4.0, 5.0, 8.0, 3.0, 6.0, 5.0, 2.0, 8.0, 7.0, 6.0, 8.0, 8.0, 7.0, 8.0,
                                  6.0, 6.0, 6.0, 7.0, 1.0, 8.0, 8.0, 0.0, 8.0, 1.0, 3.0, 7.0, 1.0, 8.0, 8.0, 5.0, 0.0, 2.0, 6.0, 9.0, 6.0, 2.0, 6.0, 5.0, 7.0, 1.0, 7.0, 5.0, 9.0, 3.0, 6.0, 9.0,
                                  1.0, 9.0, 6.0, 0.0, 3.0, 7.0, 0.0, 5.0, 3.0, 6.0, 0.0, 8.0, 9.0, 9.0, 7.0, 1.0, 7.0, 0.0, 0.0, 3.0, 4.0, 7.0, 6.0, 4.0, 2.0, 9.0, 4.0, 4.0, 1.0, 7.0, 6.0, 2.0,
                                  0.0, 6.0, 6.0, 2.0, 9.0, 1.0, 4.0, 9.0, 4.0, 6.0, 3.0, 2.0, 9.0, 4.0, 8.0, 2.0, 2.0, 0.0, 6.0, 3.0, 8.0, 4.0, 9.0, 1.0, 8.0, 7.0, 7.0, 8.0, 7.0, 6.0, 1.0, 0.0,
                                  9.0, 6.0, 7.0, 4.0, 1.0, 1.0, 6.0, 4.0, 2.0, 4.0, 0.0, 5.0, 2.0, 7.0, 3.0, 4.0, 0.0, 0.0, 3.0, 4.0, 6.0, 2.0, 6.0, 8.0, 7.0, 0.0, 4.0, 1.0, 2.0, 9.0, 1.0, 4.0,
                                  6.0, 7.0, 5.0, 0.0, 3.0, 5.0, 0.0, 3.0, 0.0, 0.0, 3.0, 1.0, 5.0, 6.0, 8.0, 2.0, 1.0, 1.0, 6.0, 7.0, 0.0, 9.0, 0.0, 5.0, 7.0, 8.0, 7.0, 8.0, 3.0, 8.0, 0.0, 8.0,
                                  5.0, 8.0, 4.0, 6.0, 5.0, 7.0, 0.0, 0.0, 2.0, 1.0, 8.0, 2.0, 9.0, 3.0, 1.0, 7.0, 6.0, 4.0, 5.0, 7.0, 2.0, 9.0, 9.0, 6.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 8.0, 7.0,
                                  7.0, 4.0, 3.0, 3.0, 9.0, 0.0, 8.0, 5.0, 4.0, 7.0, 4.0, 8.0, 9.0, 4.0, 2.0, 5.0, 9.0, 2.0, 6.0, 6.0, 7.0, 1.0, 7.0, 9.0, 1.0, 2.0, 9.0, 1.0, 8.0, 4.0, 2.0, 8.0,
                                  4.0, 5.0, 3.0, 5.0, 1.0, 3.0, 9.0, 2.0, 6.0, 3.0, 7.0, 1.0, 9.0, 4.0, 2.0, 0.0, 1.0, 5.0, 3.0, 8.0, 4.0, 2.0, 6.0, 7.0, 1.0, 1.0, 0.0, 7.0, 6.0, 4.0, 8.0, 8.0,
                                  5.0, 8.0, 2.0, 1.0, 2.0, 0.0, 5.0, 9.0, 0.0, 1.0, 4.0, 9.0, 3.0, 5.0, 0.0, 1.0, 9.0, 9.0, 0.0, 9.0, 6.0, 8.0, 4.0, 5.0, 4.0, 6.0, 1.0, 0.0, 3.0, 7.0, 2.0, 6.0,
                                  9.0, 0.0, 6.0, 4.0, 8.0, 1.0, 6.0, 8.0, 9.0, 6.0, 4.0, 6.0, 8.0, 5.0, 0.0, 9.0, 6.0, 6.0, 2.0, 6.0, 3.0, 6.0, 1.0, 6.0, 9.0, 0.0, 9.0, 4.0, 8.0, 7.0, 5.0, 7.0,
                                  8.0, 4.0, 3.0, 6.0, 8.0, 7.0, 7.0, 4.0, 8.0, 1.0, 5.0, 0.0, 3.0, 3.0, 3.0, 6.0, 3.0, 4.0, 2.0, 3.0, 2.0, 0.0, 6.0, 6.0, 6.0, 4.0, 3.0, 8.0, 5.0, 4.0, 0.0, 3.0,
                                  3.0, 3.0, 5.0, 5.0, 6.0, 7.0, 8.0, 7.0, 9.0, 0.0, 1.0, 0.0, 6.0, 8.0, 2.0, 9.0, 0.0, 9.0, 3.0, 1.0, 4.0, 2.0, 2.0, 3.0, 8.0, 5.0, 3.0, 6.0, 7.0, 2.0, 4.0, 1.0,
                                  1.0, 6.0, 1.0, 5.0, 7.0, 1.0, 5.0, 2.0, 9.0, 4.0, 8.0, 5.0, 0.0, 6.0, 9.0, 6.0, 8.0, 8.0, 2.0, 2.0, 6.0, 4.0, 8.0, 9.0, 3.0, 2.0, 7.0, 2.0, 8.0, 4.0, 6.0, 0.0,
                                  6.0, 4.0, 5.0, 1.0, 7.0, 8.0, 2.0, 0.0, 0.0, 6.0, 6.0, 5.0, 2.0, 3.0, 5.0, 4.0, 9.0, 1.0, 6.0, 4.0, 4.0, 7.0, 6.0, 9.0, 1.0, 1.0, 7.0, 5.0, 2.0, 0.0, 0.0, 8.0,
                                  1.0, 3.0, 2.0, 3.0, 0.0, 5.0, 0.0, 8.0, 2.0, 5.0, 8.0, 6.0, 5.0, 3.0, 3.0, 6.0, 9.0, 6.0, 5.0, 7.0, 4.0, 0.0, 5.0, 9.0, 1.0, 6.0, 2.0, 5.0, 0.0, 4.0, 7.0, 3.0,
                                  6.0, 7.0, 9.0, 2.0, 3.0, 1.0, 9.0, 9.0, 5.0, 8.0, 5.0, 6.0, 0.0, 7.0, 1.0, 8.0, 7.0, 7.0, 0.0, 3.0, 2.0, 3.0, 0.0, 9.0, 5.0, 3.0, 3.0, 4.0, 6.0, 5.0, 9.0, 4.0,
                                  9.0, 8.0, 2.0, 9.0, 1.0, 8.0, 3.0, 8.0, 8.0, 8.0, 7.0, 3.0, 0.0, 4.0, 1.0, 6.0, 3.0, 9.0, 6.0, 8.0, 1.0, 8.0, 9.0, 4.0, 6.0, 7.0, 1.0, 5.0, 3.0, 1.0, 3.0, 0.0,
                                  0.0, 1.0, 9.0, 5.0, 9.0, 4.0, 3.0, 5.0, 4.0, 1.0, 6.0, 2.0, 6.0, 6.0, 1.0, 0.0, 7.0, 4.0, 0.0, 9.0, 0.0, 6.0, 9.0, 2.0, 1.0, 1.0, 3.0, 1.0, 6.0, 0.0, 5.0, 9.0,
                                  8.0, 6.0, 3.0, 6.0, 5.0, 4.0, 1.0, 8.0, 4.0, 1.0, 3.0, 4.0, 8.0, 7.0, 7.0, 0.0, 4.0, 4.0, 0.0, 2.0, 7.0, 1.0, 5.0, 2.0, 0.0, 2.0, 9.0, 8.0, 9.0, 4.0, 1.0, 5.0,
                                  4.0, 8.0, 0.0, 4.0, 1.0, 3.0, 7.0, 4.0, 3.0, 3.0, 4.0, 7.0, 8.0, 9.0, 7.0, 3.0, 6.0, 4.0, 2.0, 8.0, 0.0, 9.0, 4.0, 6.0, 6.0, 8.0, 6.0, 6.0, 0.0, 5.0, 1.0, 7.0,
                                  5.0, 6.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 9.0, 7.0, 3.0, 2.0, 3.0, 7.0, 6.0, 1.0, 1.0, 0.0, 6.0, 7.0, 2.0, 0.0, 0.0, 9.0, 2.0, 7.0, 6.0, 3.0, 2.0, 1.0, 6.0, 7.0,
                                  6.0, 5.0, 0.0, 9.0, 7.0, 2.0, 9.0, 6.0, 5.0, 7.0, 8.0, 6.0, 1.0, 3.0, 9.0, 2.0, 3.0, 4.0, 4.0, 6.0, 9.0, 2.0, 1.0, 1.0, 8.0, 6.0, 2.0, 8.0, 8.0, 8.0, 9.0, 2.0,
                                  7.0, 4.0, 8.0, 7.0, 7.0, 6.0, 1.0, 5.0, 9.0, 9.0, 0.0, 1.0, 1.0, 7.0, 8.0, 2.0, 5.0, 8.0, 7.0, 5.0, 5.0, 5.0, 2.0, 5.0, 6.0, 8.0, 6.0, 7.0, 1.0, 4.0, 0.0, 2.0,
                                  7.0, 9.0, 0.0, 4.0, 8.0, 2.0, 5.0, 7.0, 6.0, 1.0, 3.0, 7.0, 5.0, 0.0, 7.0, 0.0, 7.0, 2.0, 9.0, 3.0, 3.0, 1.0, 3.0, 8.0, 9.0, 3.0, 4.0, 7.0, 8.0, 5.0, 3.0, 4.0,
                                  6.0, 0.0, 6.0, 3.0, 7.0, 0.0, 5.0, 4.0, 6.0, 0.0, 5.0, 5.0, 5.0, 6.0, 6.0, 8.0, 2.0, 8.0, 4.0, 0.0, 0.0, 3.0, 7.0, 7.0, 7.0, 5.0, 4.0, 1.0, 3.0, 4.0, 0.0, 2.0,
                                  5.0, 7.0, 9.0, 9.0, 6.0, 4.0, 6.0, 7.0, 1.0, 4.0, 8.0, 3.0, 5.0, 5.0, 1.0, 3.0, 3.0, 0.0, 0.0, 8.0, 2.0, 5.0, 2.0, 9.0, 2.0, 4.0, 8.0, 8.0, 1.0, 8.0, 4.0, 4.0,
                                  1.0, 0.0, 7.0, 4.0, 4.0, 7.0, 7.0, 1.0, 6.0, 1.0, 7.0, 6.0, 9.0, 0.0, 0.0, 2.0, 2.0, 2.0, 9.0, 2.0, 2.0, 7.0, 4.0, 7.0, 0.0, 4.0, 0.0, 0.0, 9.0, 1.0, 5.0, 4.0,
                                  3.0, 8.0, 0.0, 6.0, 9.0, 5.0, 9.0, 0.0, 4.0, 2.0, 7.0, 9.0, 2.0, 6.0, 1.0, 5.0, 4.0, 9.0, 6.0, 3.0, 1.0, 1.0, 2.0, 2.0, 8.0, 5.0, 5.0, 1.0, 8.0, 7.0, 0.0, 7.0};
            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);
        } else {
            // randomly generate matrix
            std::mt19937_64 eng(seed);
            std::uniform_real_distribution<T> dist;
            auto generator = std::bind(dist, eng);
            // define lambda function for initialization
            auto f = [&generator](int i, int j) -> T {
                return generator();
            };

            matrix.initialize(f);
        }
    }

    MPI_Comm lu_comm = MPI_COMM_NULL;
    MPI_Comm jk_comm = MPI_COMM_NULL;
    MPI_Comm k_comm = MPI_COMM_NULL;
    int rank;
    int pi, pj, pk;
    int M, N, P;
    int Ml, Nl;
    // Px refers to rows
    // Py refers to cols
    // Pz refers to height
    int Px, Py, Pz;
    int v, nlayr, Mt, Nt, t, tA11x, tA11y;
    int seed = 42;
    std::vector<T> data;
    costa::grid_layout<T> matrix;

    lu_params() = default;

    lu_params(int inpM, int inpN, int v, MPI_Comm comm) {
        int P;
        MPI_Comm_size(comm, &P);
        std::tie(Px, Py, Pz) = get_p_grid(inpM, inpN, P);
        initialize(inpM, inpN, v, Px, Py, Pz, comm);
    }

    lu_params(int inpM, int inpN, int v, int Px, int Py, int Pz, MPI_Comm comm) {
        initialize(inpM, inpN, v, Px, Py, Pz, comm);
    }

    ~lu_params() {
        free_comms();
    }

    void free_comms() {
        if (k_comm != MPI_COMM_NULL)
            MPI_Comm_free(&k_comm);
        if (jk_comm != MPI_COMM_NULL)
            MPI_Comm_free(&jk_comm);
        if (lu_comm != MPI_COMM_NULL)
            MPI_Comm_free(&lu_comm);
    }
};
}
