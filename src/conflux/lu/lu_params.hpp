#include <tuple>
#include <vector>
#include <mpi.h>
#include <conflux/lu/layout.hpp>

namespace conflux {
template <typename T>
class lu_params {
   private:
       std::tuple<int, int, int> p2X(MPI_Comm comm3D, int rank) {
           int coords[] = {-1, -1, -1};
           MPI_Cart_coords(comm3D, rank, 3, coords);
           return {coords[0], coords[1], coords[2]};
       }
       int X2p(MPI_Comm comm3D, int pi, int pj, int pk) {
           int coords[] = {pi, pj, pk};
           int rank;
           MPI_Cart_rank(comm3D, coords, &rank);
           return rank;
       }
       std::tuple<int, int, int> get_p_grid(int M, int N, int P) {
        double ratio = 1.0 * std::max(M, N) / std::min(M, N);
        int p1 = (int)std::cbrt(P / ratio);
        int p_square_root = (int)std::sqrt(P / ratio);
        int p_half_square_root = (int)std::sqrt(P / (2 * ratio));

        // if P a perfect square
        if (P == p_square_root*p_square_root) {
            return {p_square_root, p_square_root, 1};
        } else if (p_half_square_root * p_half_square_root == P/2) {
            return {p_half_square_root, p_half_square_root, 2};
        }

        int Px = p1;
        int Py = ratio * p1;
        int Pz = P / (Px * Py);

        // sort the values
        std::vector<int> dims = {Px, Py, Pz};
        std::sort(dims.rbegin(), dims.rend());

        Px = dims[0];
        Py = dims[1];
        Pz = dims[2];

        return {Px, Py, Pz};
    }

    void initialize(int inpM, int inpN, int v,
                    int Px, int Py, int Pz,
                    MPI_Comm comm) {
        this->Px = Px;
        this->Py = Py;
        this->Pz = Pz;

        P = Px * Px * Pz;

        this->v = v;

        // using coll
        // for large tiles, we cannot afford (due to memory constraints) 
        // to use MPI_Isend/MPI_Irecv instead of MPI_Put
        // so we have to use the collectives implementation
        // which uses no additional memory.
        this->use_collectives = v > 1024;

        int nLocalTilesx = (int)(std::ceil((double)inpM / (v * Px)));
        int nLocalTilesy = (int)(std::ceil((double)inpN / (v * Py)));

        M = v * Px * nLocalTilesx;
        N = v * Py * nLocalTilesy;

        nlayr = (int)((v + Pz - 1) / Pz);

        Nt = (int)(std::ceil((double)N / v));
        Mt = (int)(std::ceil((double)M / v));
        t = (int)(std::ceil((double)Nt / Py)) + 1ll;
        tA11x = (int)(std::ceil((double)Mt / Px));
        tA11y = (int)(std::ceil((double)Nt / Py));

        Ml = tA11x * v;
        Nl = tA11y * v;

        // the main 3D communicator
        int dim[] = {Px, Py, Pz};  // 3D processor grid
        int period[] = {0, 0, 0};
        int reorder = 1;
        MPI_Cart_create(comm, 3, dim, period, reorder, &lu_comm);

        // jk communicator
        int keep_dims_jk[] = {0, 1, 1};
        MPI_Cart_sub(lu_comm, keep_dims_jk, &jk_comm);

        // ik communicator
        int keep_dims_ik[] = {1, 0, 1};
        MPI_Cart_sub(lu_comm, keep_dims_ik, &ik_comm);

        // k-communicator
        int keep_dims_k[] = {0, 0, 1};
        MPI_Cart_sub(lu_comm, keep_dims_k, &k_comm);

        // i-communicator
        int keep_dims_i[] = {1, 0, 0};
        MPI_Cart_sub(lu_comm, keep_dims_i, &i_comm);

        // ij-comm // used only for verification
        int keep_dims_ij[] = {1, 1, 0};
        MPI_Cart_sub(lu_comm, keep_dims_ij, &ij_comm);

        // initialize coordinates
        MPI_Comm_rank(lu_comm, &rank);
        std::tie(pi, pj, pk) = p2X(lu_comm, rank);

        // matrix data
        data = std::vector<T>(Ml * Nl);

        // create COSTA layout descriptor
        matrix = conflux_layout(data.data(), M, N, v, 'R', lu_comm);

        InitMatrix();

        /*
        std::cout << std::setprecision(3);
        for (int p = 0; p < P; ++p) {
            if (rank == p) {
                std::cout << "Rank = (" << pi << ", " << pj << ", " << pk << "), Ml = " << Ml << ", Nl = " << Nl << std::endl;
                for (int i = 0; i < Ml; ++i) {
                    for (int j = 0; j < Nl; ++j) {
                        std::cout << data[i * Nl + j] << ", ";
                    }
                    std::cout << std::endl;
                }
                std::cout << "=====================" << std::endl;
            }
            MPI_Barrier(lu_comm);
        }
        */
    }

public:
    void InitMatrix() {
        // put all 0s
        auto f = [](int i, int j) -> T {
            return T{0};
        };

        matrix.initialize(f);

        // ranks that are not on layer 0 must have all 0s,
        // because A10Buff is extracted from A11Buff and 
        // MPI_Reduce is being called on A10Buff. 
        // If ranks for which pk!=0 don't have 0s
        // MPI_Reduce would sum all these non-zero values
        // into A10Buff, causing wrong results
        if (pk != 0) return;

        if (N == 8 && M == 8) {
            std::vector<T> generator = {
                100, 8, 2, 7, 3, 8, 200, 4,
                8, 2, 9, 2, 8, 6, 9, 9,
                300, 5, 0, 8, 9, 2, 7, 1,
                6, 4, 1, 2, 3, 7, 9, 1,
                8, 7, 100, 2, 9, 1, 1, 9,
                4, 2, 900, 3, 7, 3, 4, 5,   //pi=0, pj=1 owner of 900
                1, 3, 8, 3, 5, 5, 1, 3,
                3, 9, 2, 7, 9, 2, 3, 9};

            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);
        } else if (N == 9 && M == 9) {
            std::vector<T> generator = {
                1.0,  1.2,  1.4,  1.6,  1.8,  2.0,  2.2,  2.4,  2.6,  
                1.2,  1.0,  1.2,  1.4,  1.6,  1.8,  2.0,  2.2,  2.4,  
                1.4,  1.2,  1.0,  1.2,  1.4,  1.6,  1.8,  2.0,  2.2,  
                1.6,  1.4,  1.2,  1.0,  1.2,  1.4,  1.6,  1.8,  2.0,  
                1.8,  1.6,  1.4,  1.2,  1.0,  1.2,  1.4,  1.6,  1.8,  
                2.0,  1.8,  1.6,  1.4,  1.2,  1.0,  1.2,  1.4,  1.6,  
                2.2,  2.0,  1.8,  1.6,  1.4,  1.2,  1.0,  1.2,  1.4,  
                2.4,  2.2,  2.0,  1.8,  1.6,  1.4,  1.2,  1.0,  1.2,  
                2.6,  2.4,  2.2,  2.0,  1.8,  1.6,  1.4,  1.2,  1.0  };

            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);
        }
        else if (N == 16 && M == 16) {
            std::vector<T> generator = {
                1, 8, 2, 7, 3, 8, 2, 4, 8, 7, 5, 5, 1, 4, 4, 9,
                8, 4, 9, 2, 8, 6, 9, 9, 3, 7, 7, 7, 8, 7, 2, 8,
                3, 5, 4, 8, 9, 2, 7, 1, 2, 2, 7, 9, 8, 2, 1, 3,
                6, 4, 1, 5, 3, 7, 9, 1, 1, 3, 2, 9, 9, 5, 1, 9,
                8, 7, 100, 2, 9, 1, 1, 9, 3, 5, 8, 8, 5, 5, 3, 3,
                4, 2, 900, 3, 7, 3, 4, 5, 1, 9, 7, 7, 2, 4, 5, 2,  //pi=0, pj=1 owner of 900
                1, 9, 8, 3, 5, 5, 1, 3, 6, 8, 3, 4, 3, 9, 1, 9,
                3, 9, 2, 7, 9, 2, 3, 9, 8, 6, 3, 5, 5, 2, 2, 9,
                9, 9, 5, 4, 3, 4, 6, 6, 9, 2, 1, 5, 6, 9, 5, 7,
                3, 2, 4, 5, 2, 4, 5, 3, 6, 5, 2, 6, 2, 7, 8, 2,
                4, 4, 4, 5, 2, 5, 3, 4, 1, 7, 8, 1, 8, 8, 5, 4,
                4, 5, 9, 5, 7, 9, 2, 9, 4, 6, 4, 3, 5, 8, 1, 2,
                7, 8, 1, 4, 7, 6, 5, 7, 1, 2, 7, 3, 8, 1, 4, 4,
                7, 6, 7, 8, 2, 2, 4, 6, 6, 8, 3, 6, 5, 2, 6, 5,
                4, 5, 1, 5, 3, 7, 4, 4, 7, 5, 8, 2, 4, 7, 1, 7,
                8, 3, 2, 4, 3, 8, 1, 6, 9, 6, 3, 6, 4, 8, 7, 8};

            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);

        } else if (N == 20 && M == 20) {
            std::vector<T> generator = {
                1, 8, 2, 7, 3, 8, 2, 4, 8, 7, 5, 5, 1, 4, 4, 9, 8, 7, 1, 2,
                8, 4, 9, 2, 8, 6, 9, 9, 3, 7, 7, 7, 8, 7, 2, 8, 1, 2, 3, 4,
                3, 5, 4, 8, 9, 2, 7, 1, 2, 2, 7, 9, 8, 2, 1, 3, 3, 4, 5, 6,
                6, 4, 1, 5, 3, 7, 9, 1, 1, 3, 2, 9, 9, 5, 1, 9, 7, 8, 9, 1,
                8, 7, 100, 2, 9, 1, 1, 9, 3, 5, 8, 8, 5, 5, 3, 3, 2, 1, 4, 3,
                4, 2, 900, 3, 7, 3, 4, 5, 1, 9, 7, 7, 2, 4, 5, 2, 9, 8, 5, 6, //pi=0, pj=1 owner of 900
                1, 9, 8, 3, 5, 5, 1, 3, 6, 8, 3, 4, 3, 9, 1, 9, 3, 5, 7, 8,
                3, 9, 2, 7, 9, 2, 3, 9, 8, 6, 3, 5, 5, 2, 2, 9, 9, 7, 6, 4,
                9, 9, 5, 4, 3, 4, 6, 6, 9, 2, 1, 5, 6, 9, 5, 7, 4, 2, 8, 6,
                3, 2, 4, 5, 2, 4, 5, 3, 6, 5, 2, 6, 2, 7, 8, 2, 9, 7, 1, 2,
                4, 4, 4, 5, 2, 5, 3, 4, 1, 7, 8, 1, 8, 8, 5, 4, 1, 5, 4, 2,
                4, 5, 9, 5, 7, 9, 2, 9, 4, 6, 4, 3, 5, 8, 1, 2, 8, 7, 9, 1,
                7, 8, 1, 4, 7, 6, 5, 7, 1, 2, 7, 3, 8, 1, 4, 4, 3, 3, 1, 2,
                7, 6, 7, 8, 2, 2, 4, 6, 6, 8, 3, 6, 5, 2, 6, 5, 5, 4, 9, 8,
                4, 5, 1, 5, 3, 7, 4, 4, 7, 5, 8, 2, 4, 7, 1, 7, 1, 1, 4, 3,
                8, 3, 2, 4, 3, 8, 1, 6, 9, 6, 3, 6, 4, 8, 7, 8, 9, 5, 3, 9,
                1, 8, 2, 7, 3, 8, 2, 4, 8, 7, 5, 5, 1, 4, 4, 9, 8, 7, 1, 2,
                8, 4, 9, 2, 8, 6, 9, 9, 3, 7, 7, 7, 8, 7, 2, 8, 1, 2, 3, 4,
                3, 5, 4, 8, 9, 2, 7, 1, 2, 2, 7, 9, 8, 2, 1, 3, 3, 4, 5, 6,
                6, 4, 1, 5, 3, 7, 9, 1, 1, 3, 2, 9, 9, 5, 1, 9, 7, 8, 9, 1};

            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);

        } else if (N == 27 && M == 27) {
            std::vector<T> generator = {
                                9.0,   0.0,   7.0,   2.0, 400.0,   3.0,   2.0,   8.0,   2.0,   9.0,   6.0,   3.0,   6.0,   6.0,   7.0,   9.0,   5.0,   2.0,   0.0,   7.0,   0.0,   2.0,   8.0,   8.0,   9.0,   4.0,   5.0,
2.0,   9.0,   4.0,   6.0,   4.0,   4.0,   6.0,   5.0,   5.0,   7.0,   1.0,   7.0,   2.0,   7.0,   2.0,   9.0,   4.0,   1.0,   2.0,   2.0,   8.0,   4.0,   7.0,   3.0,   4.0,   5.0,   0.0,
0.0,   0.0,   9.0,   3.0,   2.0,   0.0,   9.0,   6.0,   7.0,   3.0,   5.0,   4.0,   9.0,   2.0,   4.0,   7.0,   0.0,   4.0,   3.0,   2.0,   4.0,   2.0,   6.0,   1.0,   8.0,   3.0,   0.0,
0.0,   5.0,   7.0,   6.0,   7.0,   1.0,   1.0,   4.0,   3.0,   8.0,   2.0,   9.0,   9.0,   7.0,   0.0,   9.0,   2.0,   9.0,   7.0,   6.0,   3.0,   9.0,   4.0,   1.0,   1.0,   7.0,   0.0,
3.0,   6.0,   6.0,   2.0,   4.0,   8.0,   3.0,   7.0,   2.0,   9.0,   6.0,   9.0,   2.0,   9.0,   1.0,   3.0,   6.0,   3.0,   0.0,   7.0,   5.0,   4.0,   6.0,  -0.0,   6.0,   7.0,   8.0,
8.0,   6.0,   6.0,   5.0,   7.0,   1.0,   4.0,   9.0,   1.0,   8.0,   1.0,   2.0,   9.0,   1.0,   1.0,   6.0,   3.0,   9.0,   0.0,   7.0,   6.0,   7.0,   5.0,   0.0,   8.0,   4.0,  -0.0,
1.0,   5.0,   8.0,   5.0,   6.0,   6.0,   9.0,   7.0,   7.0,   2.0,   0.0,   8.0,   1.0,   9.0,   1.0,   8.0,   4.0,   5.0,   3.0,   5.0,   5.0,   7.0,   2.0,   3.0,  -0.0,   5.0,   6.0,
0.0,   3.0,   0.0,   2.0,   6.0,   1.0,   3.0,   1.0,   5.0,   6.0,   7.0,   5.0,   6.0,   3.0,   9.0,   1.0,   3.0,   5.0,   1.0,   8.0,   5.0,   9.0,   3.0,   9.0,   4.0,   6.0,   5.0,
7.0,   7.0,   6.0,   9.0,   1.0,   6.0,   9.0,   3.0,   8.0,   9.0,   9.0,   3.0,   5.0,   5.0,   2.0,   1.0,   5.0,   8.0,   6.0,   8.0,   3.0,   0.0,   6.0,   2.0,   9.0,   9.0,   0.0,
4.0,   2.0,   0.0,   7.0,   0.0,   0.0,   1.0,   5.0,   4.0,   6.0,   8.0,   7.0,   0.0,   4.0,   3.0,   5.0,   3.0,   4.0,  -0.0,   1.0,   1.0,   6.0,   7.0,   1.0,   8.0,   2.0,   3.0,
9.0,   2.0,   3.0,   1.0,   6.0,   2.0,   8.0,   7.0,   1.0,   6.0,  -0.0,   8.0,   2.0,   8.0,   3.0,   8.0,   5.0,   6.0,   8.0,   3.0,   3.0,   8.0,   0.0,   5.0,   5.0,   9.0,   5.0,
2.0,   1.0,   7.0,   7.0,   7.0,   7.0,   1.0,   4.0,   1.0,   0.0,   4.0,   3.0,   0.0,   3.0,   8.0,   4.0,   6.0,   3.0,   1.0,   9.0,   8.0,   4.0,   8.0,   5.0,   8.0,   1.0,   5.0,
1.0,   6.0,   1.0,   2.0,   4.0,   1.0,   6.0,   9.0,   5.0,   3.0,   9.0,   8.0,   6.0,   3.0,   8.0,   3.0,   6.0,   0.0,   3.0,   5.0,   5.0,   8.0,   3.0,   0.0,   9.0,   3.0,   1.0,
3.0,   7.0,   1.0,   4.0,   3.0,   3.0,   3.0,   2.0,   5.0,   7.0,   9.0,  -0.0,   7.0,   7.0,   0.0,   1.0,   2.0,   1.0,   7.0,   3.0,   9.0,   5.0,   7.0,   3.0,   2.0,   7.0,   4.0,
0.0,   3.0,   5.0,   5.0,   6.0,   5.0,   2.0,   6.0,   9.0,  -0.0,   0.0,   9.0,   5.0,   0.0,   2.0,   8.0,   3.0,   8.0,   0.0,   6.0,   9.0,   8.0,   4.0,   6.0,   5.0,   1.0,   9.0,
1.0,   0.0,   1.0,   3.0,   6.0,  -0.0,   3.0,   4.0,   6.0,   4.0,   6.0,   9.0,   6.0,   5.0,   4.0,   5.0,   3.0,   1.0,   1.0,   9.0,   2.0,   9.0,   4.0,   5.0,   3.0,   7.0,  -0.0,
4.0,   7.0,   1.0,   1.0,   2.0,   3.0,   1.0,   7.0,   3.0,   8.0,   2.0,   5.0,   3.0,   6.0,   5.0,   7.0,   7.0,   6.0,   5.0,   1.0,   8.0,   5.0,   8.0,   3.0,   8.0,   4.0,   8.0,
1.0,   5.0,   3.0,   7.0,   1.0,   7.0,   0.0,   5.0,   0.0,   1.0,   3.0,   6.0,   7.0,   7.0,   7.0,   6.0,   9.0,   7.0,   9.0,   7.0,   5.0,   6.0,   2.0,   3.0,   5.0,   4.0,   4.0,
5.0,   7.0,   5.0,   3.0,   9.0,  -0.0,   1.0,   3.0,   8.0,   2.0,   3.0,   8.0,   1.0,   0.0,   6.0,   4.0,   7.0,   8.0,   2.0,   8.0,   8.0,   8.0,   2.0,   5.0,   4.0,   3.0,   8.0,
7.0,   6.0,   7.0,   8.0,   7.0,   1.0,   7.0,   2.0,   1.0,   7.0,   2.0,   6.0,   8.0,   5.0,   2.0,   3.0,   3.0,   2.0,   2.0,   5.0,   9.0,   4.0,   6.0,   3.0,   5.0,   6.0,   2.0,
2.0,   2.0,  -0.0,   0.0,   1.0,   6.0,  -0.0,   0.0,   6.0,   7.0,   3.0,   5.0,   9.0,   8.0,   1.0,   3.0,   8.0,   4.0,   8.0,   4.0,   7.0,   8.0,   4.0,   7.0,   8.0,   4.0,   1.0,
0.0,   7.0,  -0.0,   7.0,   9.0,   1.0,   6.0,   2.0,   0.0,   6.0,   8.0,   2.0,   3.0,   4.0,   1.0,   9.0,   7.0,   8.0,  -0.0,   4.0,   5.0,   3.0,   6.0,   4.0,   3.0,   8.0,   6.0,
2.0,   5.0,   7.0,   2.0,   4.0,   7.0,   6.0,   1.0,  -0.0,   4.0,   1.0,   0.0,   6.0,   7.0,   3.0,   7.0,   0.0,   6.0,   3.0,   7.0,   8.0,   2.0,   4.0,   1.0,   8.0,   7.0,   0.0,
4.0,   0.0,   7.0,   2.0,   1.0,   1.0,   4.0,   3.0,   8.0,   4.0,   7.0,   2.0,   4.0,   4.0,  -0.0,   9.0,   9.0,   3.0,   9.0,   5.0,   0.0,   4.0,   8.0,   8.0,   6.0,   7.0,   5.0,
8.0,   8.0,   7.0,   3.0,   4.0,   5.0,   2.0,   4.0,   9.0,   7.0,   1.0,   6.0,   1.0,   9.0,   7.0,   8.0,   9.0,   8.0,   3.0,   7.0,   9.0,   9.0,   8.0,   6.0,  -0.0,   5.0,   2.0,
5.0,   0.0,   1.0,  -0.0,   2.0,   1.0,   5.0,   4.0,   1.0,   5.0,   6.0,   0.0,   8.0,   5.0,   6.0,  -0.0,   6.0,   7.0,   4.0,  -0.0,   9.0,   6.0,   1.0,   3.0,   5.0,   6.0,   8.0,
1.0,   7.0,   6.0,   7.0,   0.0,   2.0,   7.0,   7.0,   4.0,   5.0,   3.0,  -0.0,   6.0,   0.0,   7.0,   6.0,   6.0,   5.0,   6.0,   4.0,   8.0,   1.0,   7.0,  -0.0,   5.0,   6.0,   6.0};

                                // 4.0, 2.0, 0.0, 7.0, 0.0, 0.0, 1.0, 5.0, 4.0, 6.0, 8.0, 7.0, 0.0, 4.0, 3.0, 5.0, 3.0, 4.0, 0.0, 1.0, 1.0, 6.0, 7.0, 1.0, 8.0, 2.0, 3.0,
                                // 9.0, 0.0, 7.0, 2.0, 400.0, 3.0, 2.0, 8.0, 2.0, 9.0, 6.0, 3.0, 6.0, 6.0, 7.0, 9.0, 5.0, 2.0, 0.0, 7.0, 0.0, 2.0, 8.0, 8.0, 9.0, 4.0, 5.0,
                                // 1.0, 5.0, 3.0, 7.0, 1.0, 7.0, 0.0, 5.0, 0.0, 1.0, 3.0, 6.0, 7.0, 7.0, 7.0, 6.0, 9.0, 7.0, 9.0, 7.0, 5.0, 6.0, 2.0, 3.0, 5.0, 4.0, 4.0,
                                // 7.0, 7.0, 6.0, 9.0, 1.0, 6.0, 9.0, 3.0, 8.0, 9.0, 9.0, 3.0, 5.0, 5.0, 2.0, 1.0, 5.0, 8.0, 6.0, 8.0, 3.0, 0.0, 6.0, 2.0, 9.0, 9.0, 0.0,
                                // 7.0, 6.0, 7.0, 8.0, 7.0, 1.0, 7.0, 2.0, 1.0, 7.0, 2.0, 6.0, 8.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 5.0, 9.0, 4.0, 6.0, 3.0, 5.0, 6.0, 2.0,
                                // 5.0, 0.0, 1.0, 0.0, 2.0, 1.0, 5.0, 4.0, 1.0, 5.0, 6.0, 0.0, 8.0, 5.0, 6.0, 0.0, 6.0, 7.0, 4.0, 0.0, 9.0, 6.0, 1.0, 3.0, 5.0, 6.0, 8.0,
                                // 1.0, 0.0, 1.0, 3.0, 6.0, 0.0, 3.0, 4.0, 6.0, 4.0, 6.0, 9.0, 6.0, 5.0, 4.0, 5.0, 3.0, 1.0, 1.0, 9.0, 2.0, 9.0, 4.0, 5.0, 3.0, 7.0, 0.0,
                                // 5.0, 7.0, 5.0, 3.0, 9.0, 0.0, 1.0, 3.0, 8.0, 2.0, 3.0, 8.0, 1.0, 0.0, 6.0, 4.0, 7.0, 8.0, 2.0, 8.0, 8.0, 8.0, 2.0, 5.0, 4.0, 3.0, 8.0,
                                // 2.0, 9.0, 4.0, 6.0, 4.0, 4.0, 6.0, 5.0, 5.0, 7.0, 1.0, 7.0, 2.0, 7.0, 2.0, 9.0, 4.0, 1.0, 2.0, 2.0, 8.0, 4.0, 7.0, 3.0, 4.0, 5.0, 0.0,
                                // 1.0, 5.0, 8.0, 5.0, 6.0, 6.0, 9.0, 7.0, 7.0, 2.0, 0.0, 8.0, 1.0, 9.0, 1.0, 8.0, 4.0, 5.0, 3.0, 5.0, 5.0, 7.0, 2.0, 3.0, 0.0, 5.0, 6.0,
                                // 2.0, 1.0, 7.0, 7.0, 7.0, 7.0, 1.0, 4.0, 1.0, 0.0, 4.0, 3.0, 0.0, 3.0, 8.0, 4.0, 6.0, 3.0, 1.0, 9.0, 8.0, 4.0, 8.0, 5.0, 8.0, 1.0, 5.0,
                                // 8.0, 8.0, 7.0, 3.0, 4.0, 5.0, 2.0, 4.0, 9.0, 7.0, 1.0, 6.0, 1.0, 9.0, 7.0, 8.0, 9.0, 8.0, 3.0, 7.0, 9.0, 9.0, 8.0, 6.0, 0.0, 5.0, 2.0,
                                // 0.0, 3.0, 0.0, 2.0, 6.0, 1.0, 3.0, 1.0, 5.0, 6.0, 7.0, 5.0, 6.0, 3.0, 9.0, 1.0, 3.0, 5.0, 1.0, 8.0, 5.0, 9.0, 3.0, 9.0, 4.0, 6.0, 5.0,
                                // 2.0, 2.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 6.0, 7.0, 3.0, 5.0, 9.0, 8.0, 1.0, 3.0, 8.0, 4.0, 8.0, 4.0, 7.0, 8.0, 4.0, 7.0, 8.0, 4.0, 1.0,
                                // 0.0, 7.0, 0.0, 7.0, 9.0, 1.0, 6.0, 2.0, 0.0, 6.0, 8.0, 2.0, 3.0, 4.0, 1.0, 9.0, 7.0, 8.0, 0.0, 4.0, 5.0, 3.0, 6.0, 4.0, 3.0, 8.0, 6.0,
                                // 4.0, 0.0, 7.0, 2.0, 1.0, 1.0, 4.0, 3.0, 8.0, 4.0, 7.0, 2.0, 4.0, 4.0, 0.0, 9.0, 9.0, 3.0, 9.0, 5.0, 0.0, 4.0, 8.0, 8.0, 6.0, 7.0, 5.0,
                                // 0.0, 0.0, 9.0, 3.0, 2.0, 0.0, 9.0, 6.0, 7.0, 3.0, 5.0, 4.0, 9.0, 2.0, 4.0, 7.0, 0.0, 4.0, 3.0, 2.0, 4.0, 2.0, 6.0, 1.0, 8.0, 3.0, 0.0,
                                // 8.0, 6.0, 6.0, 5.0, 7.0, 1.0, 4.0, 9.0, 1.0, 8.0, 1.0, 2.0, 9.0, 1.0, 1.0, 6.0, 3.0, 9.0, 0.0, 7.0, 6.0, 7.0, 5.0, 0.0, 8.0, 4.0, 0.0,
                                // 1.0, 6.0, 1.0, 2.0, 4.0, 1.0, 6.0, 9.0, 5.0, 3.0, 9.0, 8.0, 6.0, 3.0, 8.0, 3.0, 6.0, 0.0, 3.0, 5.0, 5.0, 8.0, 3.0, 0.0, 9.0, 3.0, 1.0,
                                // 0.0, 5.0, 7.0, 6.0, 7.0, 1.0, 1.0, 4.0, 3.0, 8.0, 2.0, 9.0, 9.0, 7.0, 0.0, 9.0, 2.0, 9.0, 7.0, 6.0, 3.0, 9.0, 4.0, 1.0, 1.0, 7.0, 0.0,
                                // 3.0, 7.0, 1.0, 4.0, 3.0, 3.0, 3.0, 2.0, 5.0, 7.0, 9.0, 0.0, 7.0, 7.0, 0.0, 1.0, 2.0, 1.0, 7.0, 3.0, 9.0, 5.0, 7.0, 3.0, 2.0, 7.0, 4.0,
                                // 4.0, 7.0, 1.0, 1.0, 2.0, 3.0, 1.0, 7.0, 3.0, 8.0, 2.0, 5.0, 3.0, 6.0, 5.0, 7.0, 7.0, 6.0, 5.0, 1.0, 8.0, 5.0, 8.0, 3.0, 8.0, 4.0, 8.0,
                                // 1.0, 7.0, 6.0, 7.0, 0.0, 2.0, 7.0, 7.0, 4.0, 5.0, 3.0, 0.0, 6.0, 0.0, 7.0, 6.0, 6.0, 5.0, 6.0, 4.0, 8.0, 1.0, 7.0, 0.0, 5.0, 6.0, 6.0,
                                // 9.0, 2.0, 3.0, 1.0, 6.0, 2.0, 8.0, 7.0, 1.0, 6.0, 0.0, 8.0, 2.0, 8.0, 3.0, 8.0, 5.0, 6.0, 8.0, 3.0, 3.0, 8.0, 0.0, 5.0, 5.0, 9.0, 5.0,
                                // 3.0, 6.0, 6.0, 2.0, 4.0, 8.0, 3.0, 7.0, 2.0, 9.0, 6.0, 9.0, 2.0, 9.0, 1.0, 3.0, 6.0, 3.0, 0.0, 7.0, 5.0, 4.0, 6.0, 0.0, 6.0, 7.0, 8.0,
                                // 2.0, 5.0, 7.0, 2.0, 4.0, 7.0, 6.0, 1.0, 0.0, 4.0, 1.0, 0.0, 6.0, 7.0, 3.0, 7.0, 0.0, 6.0, 3.0, 7.0, 8.0, 2.0, 4.0, 1.0, 8.0, 7.0, 0.0,
                                // 0.0, 3.0, 5.0, 5.0, 6.0, 5.0, 2.0, 6.0, 9.0, 0.0, 0.0, 9.0, 5.0, 0.0, 2.0, 8.0, 3.0, 8.0, 0.0, 6.0, 9.0, 8.0, 4.0, 6.0, 5.0, 1.0, 9.0};

            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);
        } else if (N == 32 && M == 32) {
            std::vector<T> generator = {9.0, 4.0, 8.0, 8.0, 3.0, 8.0, 0.0, 5.0, 2.0, 1.0, 0.0, 6.0, 3.0, 7.0, 0.0, 3.0, 5.0, 7.0, 3.0, 6.0, 8.0, 6.0, 2.0, 0.0, 8.0, 0.0, 8.0, 5.0, 9.0, 7.0, 9.0, 3.0,
                                  7.0, 4.0, 4.0, 6.0, 8.0, 9.0, 7.0, 4.0, 4.0, 7.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 0.0, 9.0, 4.0, 3.0, 6.0, 2.0, 9.0, 7.0, 0.0, 4.0, 8.0, 9.0, 4.0, 6.0, 1.0,
                                  9.0, 2.0, 9.0, 6.0, 6.0, 5.0, 2.0, 1.0, 2.0, 1.0, 7.0, 3.0, 0.0, 9.0, 8.0, 9.0, 9.0, 1.0, 3.0, 7.0, 6.0, 1.0, 8.0, 2.0, 2.0, 5.0, 5.0, 5.0, 0.0, 8.0, 2.0, 1.0,
                                  8.0, 9.0, 8.0, 8.0, 6.0, 5.0, 0.0, 4.0, 3.0, 2.0, 7.0, 4.0, 0.0, 2.0, 6.0, 0.0, 8.0, 4.0, 4.0, 5.0, 8.0, 3.0, 6.0, 5.0, 2.0, 8.0, 7.0, 6.0, 8.0, 8.0, 7.0, 8.0,
                                  6.0, 6.0, 6.0, 7.0, 1.0, 8.0, 8.0, 0.0, 8.0, 1.0, 3.0, 7.0, 1.0, 8.0, 8.0, 5.0, 0.0, 2.0, 6.0, 9.0, 6.0, 2.0, 6.0, 5.0, 7.0, 1.0, 7.0, 5.0, 9.0, 3.0, 6.0, 9.0,
                                  1.0, 9.0, 6.0, 0.0, 3.0, 7.0, 0.0, 5.0, 3.0, 6.0, 0.0, 8.0, 9.0, 9.0, 7.0, 1.0, 7.0, 0.0, 0.0, 3.0, 4.0, 7.0, 6.0, 4.0, 2.0, 9.0, 4.0, 4.0, 1.0, 7.0, 6.0, 2.0,
                                  0.0, 6.0, 6.0, 2.0, 9.0, 1.0, 4.0, 9.0, 4.0, 6.0, 3.0, 2.0, 9.0, 4.0, 8.0, 2.0, 2.0, 0.0, 6.0, 3.0, 8.0, 4.0, 9.0, 1.0, 8.0, 7.0, 7.0, 8.0, 7.0, 6.0, 1.0, 0.0,
                                  9.0, 6.0, 7.0, 4.0, 1.0, 1.0, 6.0, 4.0, 2.0, 4.0, 0.0, 5.0, 2.0, 7.0, 3.0, 4.0, 0.0, 0.0, 3.0, 4.0, 6.0, 2.0, 6.0, 8.0, 7.0, 0.0, 4.0, 1.0, 2.0, 9.0, 1.0, 4.0,
                                  6.0, 7.0, 5.0, 0.0, 3.0, 5.0, 0.0, 3.0, 0.0, 0.0, 3.0, 1.0, 5.0, 6.0, 8.0, 2.0, 1.0, 1.0, 6.0, 7.0, 0.0, 9.0, 0.0, 5.0, 7.0, 8.0, 7.0, 8.0, 3.0, 8.0, 0.0, 8.0,
                                  5.0, 8.0, 4.0, 6.0, 5.0, 7.0, 0.0, 0.0, 2.0, 1.0, 8.0, 2.0, 9.0, 3.0, 1.0, 7.0, 6.0, 4.0, 5.0, 7.0, 2.0, 9.0, 9.0, 6.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 8.0, 7.0,
                                  7.0, 4.0, 3.0, 3.0, 9.0, 0.0, 8.0, 5.0, 4.0, 7.0, 4.0, 8.0, 9.0, 4.0, 2.0, 5.0, 9.0, 2.0, 6.0, 6.0, 7.0, 1.0, 7.0, 9.0, 1.0, 2.0, 9.0, 1.0, 8.0, 4.0, 2.0, 8.0,
                                  4.0, 5.0, 3.0, 5.0, 1.0, 3.0, 9.0, 2.0, 6.0, 3.0, 7.0, 1.0, 9.0, 4.0, 2.0, 0.0, 1.0, 5.0, 3.0, 8.0, 4.0, 2.0, 6.0, 7.0, 1.0, 1.0, 0.0, 7.0, 6.0, 4.0, 8.0, 8.0,
                                  5.0, 8.0, 2.0, 1.0, 2.0, 0.0, 5.0, 9.0, 0.0, 1.0, 4.0, 9.0, 3.0, 5.0, 0.0, 1.0, 9.0, 9.0, 0.0, 9.0, 6.0, 8.0, 4.0, 5.0, 4.0, 6.0, 1.0, 0.0, 3.0, 7.0, 2.0, 6.0,
                                  9.0, 0.0, 6.0, 4.0, 8.0, 1.0, 6.0, 8.0, 9.0, 6.0, 4.0, 6.0, 8.0, 5.0, 0.0, 9.0, 6.0, 6.0, 2.0, 6.0, 3.0, 6.0, 1.0, 6.0, 9.0, 0.0, 9.0, 4.0, 8.0, 7.0, 5.0, 7.0,
                                  8.0, 4.0, 3.0, 6.0, 8.0, 7.0, 7.0, 4.0, 8.0, 1.0, 5.0, 0.0, 3.0, 3.0, 3.0, 6.0, 3.0, 4.0, 2.0, 3.0, 2.0, 0.0, 6.0, 6.0, 6.0, 4.0, 3.0, 8.0, 5.0, 4.0, 0.0, 3.0,
                                  3.0, 3.0, 5.0, 5.0, 6.0, 7.0, 8.0, 7.0, 9.0, 0.0, 1.0, 0.0, 6.0, 8.0, 2.0, 9.0, 0.0, 9.0, 3.0, 1.0, 4.0, 2.0, 2.0, 3.0, 8.0, 5.0, 3.0, 6.0, 7.0, 2.0, 4.0, 1.0,
                                  1.0, 6.0, 1.0, 5.0, 7.0, 1.0, 5.0, 2.0, 9.0, 4.0, 8.0, 5.0, 0.0, 6.0, 9.0, 6.0, 8.0, 8.0, 2.0, 2.0, 6.0, 4.0, 8.0, 9.0, 3.0, 2.0, 7.0, 2.0, 8.0, 4.0, 6.0, 0.0,
                                  6.0, 4.0, 5.0, 1.0, 7.0, 8.0, 2.0, 0.0, 0.0, 6.0, 6.0, 5.0, 2.0, 3.0, 5.0, 4.0, 9.0, 1.0, 6.0, 4.0, 4.0, 7.0, 6.0, 9.0, 1.0, 1.0, 7.0, 5.0, 2.0, 0.0, 0.0, 8.0,
                                  1.0, 3.0, 2.0, 3.0, 0.0, 5.0, 0.0, 8.0, 2.0, 5.0, 8.0, 6.0, 5.0, 3.0, 3.0, 6.0, 9.0, 6.0, 5.0, 7.0, 4.0, 0.0, 5.0, 9.0, 1.0, 6.0, 2.0, 5.0, 0.0, 4.0, 7.0, 3.0,
                                  6.0, 7.0, 9.0, 2.0, 3.0, 1.0, 9.0, 9.0, 5.0, 8.0, 5.0, 6.0, 0.0, 7.0, 1.0, 8.0, 7.0, 7.0, 0.0, 3.0, 2.0, 3.0, 0.0, 9.0, 5.0, 3.0, 3.0, 4.0, 6.0, 5.0, 9.0, 4.0,
                                  9.0, 8.0, 2.0, 9.0, 1.0, 8.0, 3.0, 8.0, 8.0, 8.0, 7.0, 3.0, 0.0, 4.0, 1.0, 6.0, 3.0, 9.0, 6.0, 8.0, 1.0, 8.0, 9.0, 4.0, 6.0, 7.0, 1.0, 5.0, 3.0, 1.0, 3.0, 0.0,
                                  0.0, 1.0, 9.0, 5.0, 9.0, 4.0, 3.0, 5.0, 4.0, 1.0, 6.0, 2.0, 6.0, 6.0, 1.0, 0.0, 7.0, 4.0, 0.0, 9.0, 0.0, 6.0, 9.0, 2.0, 1.0, 1.0, 3.0, 1.0, 6.0, 0.0, 5.0, 9.0,
                                  8.0, 6.0, 3.0, 6.0, 5.0, 4.0, 1.0, 8.0, 4.0, 1.0, 3.0, 4.0, 8.0, 7.0, 7.0, 0.0, 4.0, 4.0, 0.0, 2.0, 7.0, 1.0, 5.0, 2.0, 0.0, 2.0, 9.0, 8.0, 9.0, 4.0, 1.0, 5.0,
                                  4.0, 8.0, 0.0, 4.0, 1.0, 3.0, 7.0, 4.0, 3.0, 3.0, 4.0, 7.0, 8.0, 9.0, 7.0, 3.0, 6.0, 4.0, 2.0, 8.0, 0.0, 9.0, 4.0, 6.0, 6.0, 8.0, 6.0, 6.0, 0.0, 5.0, 1.0, 7.0,
                                  5.0, 6.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 9.0, 7.0, 3.0, 2.0, 3.0, 7.0, 6.0, 1.0, 1.0, 0.0, 6.0, 7.0, 2.0, 0.0, 0.0, 9.0, 2.0, 7.0, 6.0, 3.0, 2.0, 1.0, 6.0, 7.0,
                                  6.0, 5.0, 0.0, 9.0, 7.0, 2.0, 9.0, 6.0, 5.0, 7.0, 8.0, 6.0, 1.0, 3.0, 9.0, 2.0, 3.0, 4.0, 4.0, 6.0, 9.0, 2.0, 1.0, 1.0, 8.0, 6.0, 2.0, 8.0, 8.0, 8.0, 9.0, 2.0,
                                  7.0, 4.0, 8.0, 7.0, 7.0, 6.0, 1.0, 5.0, 9.0, 9.0, 0.0, 1.0, 1.0, 7.0, 8.0, 2.0, 5.0, 8.0, 7.0, 5.0, 5.0, 5.0, 2.0, 5.0, 6.0, 8.0, 6.0, 7.0, 1.0, 4.0, 0.0, 2.0,
                                  7.0, 9.0, 0.0, 4.0, 8.0, 2.0, 5.0, 7.0, 6.0, 1.0, 3.0, 7.0, 5.0, 0.0, 7.0, 0.0, 7.0, 2.0, 9.0, 3.0, 3.0, 1.0, 3.0, 8.0, 9.0, 3.0, 4.0, 7.0, 8.0, 5.0, 3.0, 4.0,
                                  6.0, 0.0, 6.0, 3.0, 7.0, 0.0, 5.0, 4.0, 6.0, 0.0, 5.0, 5.0, 5.0, 6.0, 6.0, 8.0, 2.0, 8.0, 4.0, 0.0, 0.0, 3.0, 7.0, 7.0, 7.0, 5.0, 4.0, 1.0, 3.0, 4.0, 0.0, 2.0,
                                  5.0, 7.0, 9.0, 9.0, 6.0, 4.0, 6.0, 7.0, 1.0, 4.0, 8.0, 3.0, 5.0, 5.0, 1.0, 3.0, 3.0, 0.0, 0.0, 8.0, 2.0, 5.0, 2.0, 9.0, 2.0, 4.0, 8.0, 8.0, 1.0, 8.0, 4.0, 4.0,
                                  1.0, 0.0, 7.0, 4.0, 4.0, 7.0, 7.0, 1.0, 6.0, 1.0, 7.0, 6.0, 9.0, 0.0, 0.0, 2.0, 2.0, 2.0, 9.0, 2.0, 2.0, 7.0, 4.0, 7.0, 0.0, 4.0, 0.0, 0.0, 9.0, 1.0, 5.0, 4.0,
                                  3.0, 8.0, 0.0, 6.0, 9.0, 5.0, 9.0, 0.0, 4.0, 2.0, 7.0, 9.0, 2.0, 6.0, 1.0, 5.0, 4.0, 9.0, 6.0, 3.0, 1.0, 1.0, 2.0, 2.0, 8.0, 5.0, 5.0, 1.0, 8.0, 7.0, 0.0, 7.0};
            // define lambda function for initialization
            int lld = N;
            auto f = [&generator, &lld](int i, int j) -> T {
                auto value = generator[i * lld + j];
                return value;
            };

            matrix.initialize(f);
        } else {
            // randomly generate matrix
            std::mt19937_64 eng(seed + rank);
            std::uniform_real_distribution<T> dist;
            auto generator = std::bind(dist, eng);
            // define lambda function for initialization
            auto f = [&generator](int i, int j) -> T {
                return 5 + generator();
            };

            matrix.initialize(f);
        }
    }

    MPI_Comm lu_comm = MPI_COMM_NULL;
    MPI_Comm jk_comm = MPI_COMM_NULL;
    MPI_Comm ik_comm = MPI_COMM_NULL;
    MPI_Comm ij_comm = MPI_COMM_NULL;
    MPI_Comm k_comm = MPI_COMM_NULL;
    MPI_Comm i_comm = MPI_COMM_NULL;
    int rank;
    int pi, pj, pk;
    int M, N, P;
    int Ml, Nl;
    // Px refers to rows
    // Py refers to cols
    // Pz refers to height
    int Px, Py, Pz;
    int v, nlayr, Mt, Nt, t, tA11x, tA11y;
    int seed = 42;
    std::vector<T> data;
    costa::grid_layout<T> matrix;

    bool use_collectives = false;

    lu_params() = default;

    lu_params(int inpM, int inpN, int v, MPI_Comm comm) {
        MPI_Comm_size(comm, &P);
        std::tie(Px, Py, Pz) = get_p_grid(inpM, inpN, P);
        initialize(inpM, inpN, v, Px, Py, Pz, comm);
    }

    lu_params(int inpM, int inpN, int v, int Px, int Py, int Pz, MPI_Comm comm) {
        initialize(inpM, inpN, v, Px, Py, Pz, comm);
    }

    ~lu_params() {
        free_comms();
    }

    /*
    // copy-constructor not supported
    lu_params(lu_params& other) = delete;
    // copy-operator disabled
    lu_params& operator=(lu_params&) = delete;

    // assignment operators supported
    lu_params& operator=(lu_params&& other) {
        if (this != &other) {
            if (lu_comm != MPI_COMM_NULL) {
                this->free_comms();
            }
            this->lu_comm = other.lu_comm;
            this->jk_comm = other.jk_comm;
            this->ik_comm = other.ik_comm;
            this->ij_comm = other.ij_comm;
            this->k_comm = other.k_comm;
            this->i_comm = other.i_comm;
        }
        return *this;
    }
    */

    void free_comms() {
        if (i_comm != MPI_COMM_NULL)
            MPI_Comm_free(&i_comm);
        if (k_comm != MPI_COMM_NULL)
            MPI_Comm_free(&k_comm);
        if (ij_comm != MPI_COMM_NULL)
            MPI_Comm_free(&ij_comm);
        if (jk_comm != MPI_COMM_NULL)
            MPI_Comm_free(&jk_comm);
        if (ik_comm != MPI_COMM_NULL)
            MPI_Comm_free(&ik_comm);
        if (lu_comm != MPI_COMM_NULL)
            MPI_Comm_free(&lu_comm);

        i_comm = MPI_COMM_NULL;
        k_comm = MPI_COMM_NULL;
        ij_comm = MPI_COMM_NULL;
        ik_comm = MPI_COMM_NULL;
        jk_comm = MPI_COMM_NULL;
        lu_comm = MPI_COMM_NULL;
    }
};
}
